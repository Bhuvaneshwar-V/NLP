{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95dfb30",
   "metadata": {},
   "source": [
    "### Import the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d9b70e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "import string\n",
    "import spacy\n",
    "np.random.seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686989e7",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62e0904",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32e30d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af2e748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>fc27bf5d8ed568e0</td>\n",
       "      <td>Take a look at this\\n\\nWikipedia:Disruptive ed...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>fc2828355aed9e5e</td>\n",
       "      <td>Your Edits to Albert Einstein</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>fc284cc939fea168</td>\n",
       "      <td>RFC error \\nFor some reason the  replaced your...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>fc29b8a68f192b65</td>\n",
       "      <td>\"\\n Darwin Rebellion \\n\\nMy apologies for that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>fc2a808948207a7b</td>\n",
       "      <td>Ambrosi\\nThank you for experimenting with the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                       comment_text  \\\n",
       "995  fc27bf5d8ed568e0  Take a look at this\\n\\nWikipedia:Disruptive ed...   \n",
       "996  fc2828355aed9e5e                      Your Edits to Albert Einstein   \n",
       "997  fc284cc939fea168  RFC error \\nFor some reason the  replaced your...   \n",
       "998  fc29b8a68f192b65  \"\\n Darwin Rebellion \\n\\nMy apologies for that...   \n",
       "999  fc2a808948207a7b  Ambrosi\\nThank you for experimenting with the ...   \n",
       "\n",
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "995      0             0        0       0       0              0  \n",
       "996      0             0        0       0       0              0  \n",
       "997      0             0        0       0       0              0  \n",
       "998      0             0        0       0       0              0  \n",
       "999      0             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9359117d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the dataset\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "423cc493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target column distribution\n",
    "df['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db283d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nine', 'formerly', 'nothing', 'other', 'either', 'ourselves', 'no', 'into', 'front', 'through', 'seem', 'hereby', 'under', 'become', '‘d', 'became', 'off', 'becomes', 'less', 'please', 'whereby', 'out', 'them', 'therefore', 'former', 'two', 'every', 'moreover', 'around', 'various', 'nobody', \"'ve\", 'full', 'against', \"n't\", 'your', 'we', 'a', 'whole', 'thereupon', 'whereas', 'move', \"'d\", 'made', 'four', 'amongst', \"'m\", 'amount', 'else', 'themselves', 'sometime', 'what', 'beyond', 'show', 'yourselves', 'which', 'mostly', 'still', 'thru', 'becoming', 'forty', 'behind', 'from', 'whenever', 'done', 'everything', 'now', 'you', 'without', 'otherwise', 'anyone', 'an', 'himself', 'up', 'more', 'something', 'anyway', 'not', 'rather', 'many', 'least', 'whereafter', 'six', 'others', 'five', 'could', 'then', 'get', 'three', 'will', 'thereafter', 'and', 'both', 'empty', 'wherever', 'he', 'noone', 'whither', 'yours', 'since', 'just', 'yet', 'sometimes', 'why', 'same', 'along', 'latterly', 'as', 'call', 'ever', 'although', 'do', 'nevertheless', 'my', 'yourself', 'after', 'so', 'due', 'myself', 'but', 'she', 'per', 'nowhere', 'this', 'together', 'may', 'whose', 'neither', 'whether', '’d', 'down', 'thereby', 'back', 'whence', 'somehow', 'among', 'of', 'that', 'even', 'onto', 'fifty', 'being', '‘ve', 'before', '‘ll', 'fifteen', 'anyhow', 'unless', 'seemed', 'be', 'when', 'or', 'last', 'too', '’ve', 'n‘t', 'throughout', \"'re\", 'twelve', 'it', 'already', 'one', 'bottom', 'another', 'our', 'third', 'own', 'however', 'hence', 'somewhere', 'its', 'seems', 'eight', 'about', 'whereupon', 'while', 'used', 'side', 'put', 'hundred', 'latter', 'on', 'whoever', 'eleven', 'upon', 'really', 'someone', 'hereafter', 'were', 'above', '’m', 'once', 'cannot', 'if', 'everyone', 'only', 'over', 'often', 'twenty', 'the', 'itself', 'their', 'was', 'again', 'did', 'whom', '’re', 'might', 'name', 'ca', 'never', '’ll', 'first', 'whatever', 'perhaps', 'beforehand', 'nor', 'to', 'doing', 'who', 'us', 'in', 'serious', 'does', 'where', 'via', '‘m', 'except', 'thence', 'give', 'several', 'wherein', 'well', 'between', 'across', 'been', 'because', 'meanwhile', 'beside', 'would', 'always', \"'s\", 'any', 'none', 'i', 'very', 'is', 'n’t', 'than', 'must', 'can', 'had', 'take', 'ten', 'herself', 're', 'these', 'each', 'should', 'has', 'me', 'alone', 'they', 'some', 'quite', 'am', 'by', 'hers', 'with', 'hereupon', 'until', 'besides', 'within', 'for', 'go', 'make', 'keep', 'therein', 'namely', 'have', 'are', 'below', 'say', 'him', 'there', 'much', 'everywhere', 'at', 'his', 'towards', 'those', '’s', 'see', 'during', 'thus', 'top', \"'ll\", 'such', 'elsewhere', 'her', '‘s', 'anything', 'enough', 'next', 'few', 'ours', 'using', 'also', 'sixty', 'all', 'mine', 'indeed', 'toward', 'part', 'almost', 'how', 'regarding', 'here', 'seeming', '‘re', 'most', 'further', 'afterwards', 'anywhere', 'herein', 'though'}\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = nlp.Defaults.stop_words\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "300d5ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "punctuations = string.punctuation\n",
    "print(punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c433d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our tokenizer function\n",
    "\n",
    "def spacy_tokenizer(sentence):\n",
    "    \n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() for word in doc ]\n",
    "\n",
    "    # print(mytokens)\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a1529ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eat', 'apple']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"I am eating apple ?\"\n",
    "spacy_tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00541d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count Vectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3fa083f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.fit_transform([\"I am eating apple, I like apple\",\"I am playing cricket\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b02dc3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['apple', 'cricket', 'eat', 'like', 'play'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9774ee3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat': 2, 'apple': 0, 'like': 3, 'play': 4, 'cricket': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "402b21c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into independent and dependent\n",
    "\n",
    "x = df['comment_text']\n",
    "y = df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8059c0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, stratify = y, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a08c52fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= count_vectorizer.fit_transform(x_train)\n",
    "X_test = count_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14bd6193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<800x6068 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16476 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be55259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 3, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7eb0f73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 6068)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07aa3024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6068)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad707a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b50f3448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2111501e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bab3576",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe384a47",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa0af47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a506c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracy  0.83\n"
     ]
    }
   ],
   "source": [
    "Accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Acuracy \", Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3010e05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision  0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "Precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision \", Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac5894ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall  0.87\n"
     ]
    }
   ],
   "source": [
    "Recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall \", Recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
